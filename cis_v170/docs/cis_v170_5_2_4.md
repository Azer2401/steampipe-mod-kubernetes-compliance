## Description

Resource limits provide a way to constrain the amount of CPU, memory, and other resources that a container can use. This prevents resource exhaustion attacks and ensures fair resource allocation across all containers in the cluster.

## Rationale

Setting resource limits is crucial for:

1. **Resource Exhaustion Prevention**: Prevents containers from consuming all available resources
2. **Fair Resource Allocation**: Ensures all containers get their fair share of resources
3. **Cost Control**: Prevents runaway processes from consuming excessive resources
4. **Stability**: Maintains cluster stability and performance
5. **Security**: Prevents resource-based denial of service attacks

## Impact

- **Security**: Prevents resource exhaustion attacks
- **Performance**: Ensures predictable resource allocation
- **Cost**: Controls resource consumption and costs
- **Stability**: Maintains cluster stability

## Audit

Check if containers have both CPU and memory limits defined in their resource specifications.

## Remediation

### Option 1: Resource Limits in Pod Spec

Define resource limits in your pod specifications:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-limits
spec:
  containers:
  - name: app
    image: nginx:latest
    resources:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "250m"
        memory: "256Mi"
```

### Option 2: Resource Quotas

Use resource quotas at the namespace level:

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: production
spec:
  hard:
    requests.cpu: "4"
    requests.memory: 4Gi
    limits.cpu: "8"
    limits.memory: 8Gi
```

### Option 3: Limit Ranges

Use limit ranges to set default limits:

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: default-limits
  namespace: production
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
    type: Container
```

## Best Practices

### CPU Limits

- Use millicores (m) for CPU specifications
- Set reasonable limits based on application requirements
- Monitor CPU usage to optimize limits

```yaml
resources:
  limits:
    cpu: "1000m"  # 1 CPU core
  requests:
    cpu: "500m"   # 0.5 CPU core
```

### Memory Limits

- Use Mi or Gi for memory specifications
- Set limits slightly higher than expected usage
- Monitor memory usage to prevent OOM kills

```yaml
resources:
  limits:
    memory: "1Gi"
  requests:
    memory: "512Mi"
```

### HPA Integration

Combine with Horizontal Pod Autoscaler:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

## Monitoring

Monitor resource usage to optimize limits:

```bash
# Check resource usage
kubectl top pods

# Check resource quotas
kubectl describe resourcequota

# Check limit ranges
kubectl describe limitrange
```

## Default Value

By default, containers have no resource limits, which can lead to resource exhaustion.

## References

- [Kubernetes Resource Management](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- [Resource Quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/)
- [Limit Ranges](https://kubernetes.io/docs/concepts/policy/limit-range/)
- [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) 